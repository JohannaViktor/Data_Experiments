{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting if loans will be paid back\n",
    "clean data: filter and deal with missing values <br>\n",
    "try different prediction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy \n",
    "\n",
    "\n",
    "loans_2007=pd.read_csv('loans_2007.csv')\n",
    "print(loans_2007.head(1),loans_2007.shape[1])\n",
    "\n",
    "#remove columns that give away information about the future\n",
    "\n",
    "loans_2007.drop(['id','member_id','funded_amnt','funded_amnt_inv','grade','sub_grade','emp_title','issue_d'],axis=1, inplace=True)\n",
    "\n",
    "loans_2007=loans_2007.drop(['zip_code','out_prncp','out_prncp_inv','total_pymnt','total_pymnt_inv','total_rec_prncp'],axis=1)\n",
    "\n",
    "loans_2007=loans_2007.drop(['total_rec_int','total_rec_late_fee','recoveries','collection_recovery_fee','last_pymnt_amnt','last_pymnt_d'],axis=1)\n",
    "#Removing single value columns ##\n",
    "\n",
    "columns_to_drop=[]\n",
    "for col in loans_2007.columns:\n",
    "    #loans_2007[col]=loans_2007[col].dropna()\n",
    "    if len(loans_2007[col].dropna().unique())==1:\n",
    "        columns_to_drop.append(col)\n",
    "loans_2007=loans_2007.drop(columns_to_drop,axis=1)\n",
    "\n",
    "print(loans_2007.head(),loans_2007.shape[1])\n",
    "\n",
    "\n",
    "#decide on the target column: loan_status\n",
    "print(loans_2007['loan_status'].value_counts())\n",
    "\n",
    "#goal: binary classification if loan will be paid back or not, reduction to two outcomes\n",
    "loans_2007=loans_2007.loc[(loans_2007['loan_status']=='Fully Paid')|(loans_2007['loan_status']=='Charged Off')]\n",
    "map_dict={'Fully Paid':1,\n",
    "          'Charged Off':0}\n",
    "\n",
    "loans_2007['loan_status']=loans_2007['loan_status'].replace(map_dict)\n",
    "print(loans_2007['loan_status'].unique())\n",
    "\n",
    "#result is filtered data\n",
    "                          \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## further cleaning of data: handling missing values ##\n",
    "\n",
    "#import pandas as pd\n",
    "loans=loans_2007\n",
    "\n",
    "#check amount of missing values\n",
    "\n",
    "null_counts=loans.isnull().sum()\n",
    "print_null_counts=null_counts[null_counts!=0]\n",
    "print(print_null_counts)\n",
    "print(type(null_counts))\n",
    "\n",
    "## Handling missing values: drop column with mostly NaNs, drop rows with mostly NaNs: ##\n",
    "\n",
    "loans=loans.drop('pub_rec_bankruptcies',axis=1)\n",
    "loans=loans.dropna(axis=0)\n",
    "check=loans.isnull().sum()\n",
    "print(check[check>0])\n",
    "print(loans.dtypes.value_counts())\n",
    "\n",
    "## turn categorical columns into numerical columns##\n",
    "\n",
    "object_columns_df=loans.select_dtypes(include=['object'])\n",
    "print(object_columns_df.head(1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 7. Categorical columns ##\n",
    "\n",
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "loans=loans.replace(mapping_dict)\n",
    "\n",
    "## title and purpose give same information, purpose has less unique values: drop title; also drop other columns that can't be easliy converted into numbers ##\n",
    "\n",
    "print(loans['title'].value_counts())\n",
    "print(loans['purpose'].value_counts())\n",
    "loans=loans.drop(['last_credit_pull_d', 'addr_state', 'title', 'earliest_cr_line'],axis=1)\n",
    "\n",
    "#int_Rate and revol_util are numerical if % is removed:\n",
    "\n",
    "for l in ['int_rate', 'revol_util']: \n",
    "    loans[l]=(loans[l].str.rstrip('%')).astype('float')\n",
    "\n",
    "## Dummy variables for few unique categorical values ##\n",
    "cols = ['home_ownership', 'verification_status', 'emp_length', 'term', 'addr_state']\n",
    "for col in cols:\n",
    "    print(loans[col].value_counts())\n",
    "    \n",
    "dummy_df=pd.get_dummies(loans[['home_ownership','verification_status','purpose','term']])\n",
    "loans=pd.concat([loans,dummy_df],axis=1)\n",
    "loans=loans.drop(['home_ownership','verification_status','purpose','term'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try different models : goal: conservative investor, get nearly all loans paid back\n",
    "1 assume all loans are paid back <br>\n",
    "2 Logistic Regression <br>\n",
    "3 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(loans.info())\n",
    "\n",
    "## Picking an error metric ##\n",
    "\n",
    "\n",
    "#tn=len(predictions[(predictions==0)&(loans['loan_status']==0)])\n",
    "#tp=len(predictions[(predictions==1)&(loans['loan_status']==1)])\n",
    "#fn=len(predictions[(predictions==0)&(loans['loan_status']==1)])\n",
    "#fp=len(predictions[(predictions==1)&(loans['loan_status']==0)])\n",
    "\n",
    "\n",
    "print(predictions.head(1))\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "                   \n",
    "\n",
    "#realize Class imbalance - will be dealt with later\n",
    "\n",
    "# 1. first SIMPLE model: Realize good accuracy when predicting that all loans will be paid off on time (imbalance!)\n",
    "predictions = pd.Series(numpy.ones(loans.shape[0]))\n",
    "\n",
    "tn=len(predictions[(predictions==0)&(loans['loan_status']==0)])\n",
    "tp=len(predictions[(predictions==1)&(loans['loan_status']==1)])\n",
    "fn=len(predictions[(predictions==0)&(loans['loan_status']==1)])\n",
    "fp=len(predictions[(predictions==1)&(loans['loan_status']==0)])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)\n",
    "\n",
    "## 2. Logistic Regression simple model ##\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "features=loans.drop('loan_status', axis=1)\n",
    "target=loans['loan_status']\n",
    "lr.fit(features,target)\n",
    "predictions=lr.predict(features)\n",
    "#print(predictions.values_count())\n",
    "\n",
    "tp=len(predictions[(predictions==1)&(target==1)])\n",
    "fp=len(predictions[(predictions==1)&(target==0)])\n",
    "tn=len(predictions[(predictions==0)&(target==0)])\n",
    "fn=len(predictions[(predictions==0)&(target==1)])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr=fp/(tn+fp)\n",
    "print(fpr,tpr)\n",
    "\n",
    "## 2a. Logistic Regression including Cross Validation ##\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "lr = LogisticRegression()\n",
    "predictions=cross_val_predict(lr,features,target,cv=3)\n",
    "predictions=pd.Series(predictions)\n",
    "\n",
    "tp=len(predictions[(predictions==1)&(target==1)])\n",
    "fp=len(predictions[(predictions==1)&(target==0)])\n",
    "tn=len(predictions[(predictions==0)&(target==0)])\n",
    "fn=len(predictions[(predictions==0)&(target==1)])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr=fp/(tn+fp)\n",
    "print(fpr,tpr)\n",
    "\n",
    "\n",
    "## 2b address the imbalance: Penalizing the classifier ##\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "predictions=cross_val_predict(lr,features,target,cv=3)\n",
    "predictions=pd.Series(predictions)\n",
    "\n",
    "tp=len(predictions[(predictions==1)&(target==1)])\n",
    "fp=len(predictions[(predictions==1)&(target==0)])\n",
    "tn=len(predictions[(predictions==0)&(target==0)])\n",
    "fn=len(predictions[(predictions==0)&(target==1)])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr=fp/(tn+fp)\n",
    "print(fpr,tpr)\n",
    "\n",
    "## 2c increase penalties manually##\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "penalty={\n",
    "    0:10,\n",
    "    1:1\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(class_weight=penalty)\n",
    "predictions=cross_val_predict(lr,features,target,cv=3)\n",
    "predictions=pd.Series(predictions)\n",
    "\n",
    "tp=len(predictions[(predictions==1)&(target==1)])\n",
    "fp=len(predictions[(predictions==1)&(target==0)])\n",
    "tn=len(predictions[(predictions==0)&(target==0)])\n",
    "fn=len(predictions[(predictions==0)&(target==1)])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr=fp/(tn+fp)\n",
    "print(fpr,tpr)\n",
    "\n",
    "\n",
    "## 3 Model Random forests ##\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.cross_validation import cross_val_predict\n",
    "penalty={\n",
    "    0:10,\n",
    "    1:1\n",
    "}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced',random_state=1)\n",
    "predictions=cross_val_predict(rf,features,target,cv=3)\n",
    "predictions=pd.Series(predictions)\n",
    "\n",
    "tp=len(predictions[(predictions==1)&(target==1)])\n",
    "fp=len(predictions[(predictions==1)&(target==0)])\n",
    "tn=len(predictions[(predictions==0)&(target==0)])\n",
    "fn=len(predictions[(predictions==0)&(target==1)])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr=fp/(tn+fp)\n",
    "print(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## further tuning necessary\n",
    "try ensemle of models, other models,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
